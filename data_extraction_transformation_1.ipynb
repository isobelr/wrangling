{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FIT5196 Assessment 1: Task 1\n",
    "#### Student Name: Isobel Rowe\n",
    "#### Student ID: 30042585\n",
    "\n",
    "Date: 11/04/2019\n",
    "\n",
    "Version: 3.0\n",
    "\n",
    "Environment: Python 3.6.0 and Anaconda 4.3.0 (64-bit)\n",
    "\n",
    "Libraries used:\n",
    "* re\n",
    "* json\n",
    "\n",
    "## 1. Introduction\n",
    "\n",
    "This task of assignment 1 in FIT5196 deals with the extraction of data from semi-structured files. It involves using the provided file to extract and transform data into the XML and JSON formats. Broadly, the steps are as follows:\n",
    "\n",
    "1. Opening the file and extracting the data.\n",
    "2. Extracting the relevant data, including:\n",
    "    * unit ID\n",
    "    * title\n",
    "    * synopsis\n",
    "    * pre-requisites\n",
    "    * prohibitions\n",
    "    * outcomes\n",
    "    * chief examiners\n",
    "3. Transforming the parsed data into the specified formats.\n",
    "\n",
    "More details for each task will be given in the following sections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Opening file and initial extraction\n",
    "\n",
    "To begin, the .txt file is opened. I noticed that the information for each unit started with: '<div class=\"content-inner__main\"', so a loop is used to run through the file to extract the information for each unit using the .startswith() method. Then, this information is appended into a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length:  400\n"
     ]
    }
   ],
   "source": [
    "# Defining an empty list for the information to be appended to.\n",
    "htmlelements = []\n",
    "\n",
    "#Opening the file and executing a loop\n",
    "with open('30042585.txt') as file:\n",
    "    for line in file:\n",
    "        if line.startswith('<div class=\"content-inner__main\">'):\n",
    "            htmlelements.append(line)\n",
    "        else:\n",
    "            htmlelements[-1] += line\n",
    "\n",
    "#Verification that the loop worked and all sections have been properly extracted\n",
    "print(\"Length: \", len(htmlelements))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Secondary extraction with regex\n",
    "\n",
    "Next, using regular expressions, the relevant information (as per the assignment specifications) is extracted. This information is appended into separate lists, and is then validated by checking that the length of the lists are equal to 400. \n",
    "\n",
    "The regular expressions used here all differ from one another, but mostly all use either positive lookbehinds or lookaheads, or both. This is a great tool as most often, we are able to isolate the relevant information by looking for everything in between the HTML tags.\n",
    "\n",
    "### Unit ID / title / synopsis extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of unit id:  400\n",
      "Length of titles:  400\n",
      "Length of synopsis:  400\n"
     ]
    }
   ],
   "source": [
    "# Unit ID\n",
    "unitid = []\n",
    "for element in htmlelements:\n",
    "    unitre = re.findall('(?<=\\\"unitcode\\\">)\\w{3,4}\\d{4}', element) #unitcodes\n",
    "    unitid.append(unitre)\n",
    "print(\"Length of unit id: \", len(unitid))\n",
    "\n",
    "# Title\n",
    "title = []   \n",
    "for element in htmlelements:\n",
    "    titlere = re.findall('(?<=-\\s)\\w.*(?=<span class=)', element) #unit title\n",
    "    title.append(titlere)\n",
    "print(\"Length of titles: \", len(title))\n",
    "\n",
    "# Synopsis\n",
    "synopsis = []\n",
    "for element in htmlelements:\n",
    "    synopsisre = re.findall('(?<=Synopsis</h2>\\n<div>\\n<p>)\\w.*(?=</p>)', element) #synopsis\n",
    "    synopsis.append(synopsisre)\n",
    "    # Ensuring any null values are filled with 'NA'\n",
    "    if not synopsisre:\n",
    "        synopsis.pop()\n",
    "        synopsis.append('NA')\n",
    "print(\"Length of synopsis: \", len(synopsis))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prerequisite extraction\n",
    "\n",
    "Here, it starts to get a little bit trickier. As an initial step, the tags (?=Prerequisites) and (?=<p class) are used to capture everything as there is no defined layout format for pre-requisites in the HTML file. Next, using this intial extraction, the unit codes are found. Finally, any duplicate values in a single element are removed using a set to ensure uniqueness. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of pre-requisites:  400\n"
     ]
    }
   ],
   "source": [
    "# Initial extraction between the tags\n",
    "prereqs1 = []\n",
    "for element in htmlelements:\n",
    "    prereqsre1 = re.findall('(?=Prerequisites)(.*?)(?=<p class)', element, flags=re.DOTALL)\n",
    "    prereqs1.append(prereqsre1)\n",
    "    \n",
    "# Second extraction of unit codes\n",
    "prereqs2 = []\n",
    "for element in prereqs1:\n",
    "    prereqsre = re.findall('\\w{3,4}\\d{4}', str(element))\n",
    "    prereqs2.append(prereqsre)\n",
    "    if not prereqsre:\n",
    "        prereqs2.pop()\n",
    "        prereqs2.append('NA')\n",
    "\n",
    "# Removing duplicate values\n",
    "prereqs = []\n",
    "for element in prereqs2:\n",
    "    if element == 'NA':\n",
    "        prereqs.append(element)\n",
    "    else:\n",
    "        setelement = set(element)\n",
    "        prereqs.append(list(setelement))\n",
    "        \n",
    "# Verification\n",
    "print(\"Length of pre-requisites: \", len(prereqs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prohibition extraction\n",
    "Similar to the pre-requisite extraction, this was a little bit more difficult as the prohibitions don't all follow the same format. Once again, the easiest way is to first extract everything between the two tags, and then the actual unit codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of prohibitions:  400\n"
     ]
    }
   ],
   "source": [
    "#Initial regex for extraction\n",
    "prohibs1 = []\n",
    "for element in htmlelements:\n",
    "    prohibsre1 = re.findall('(?=Prohibitions)(.*?)(?=<h2)', element, flags=re.DOTALL) #synopsis\n",
    "    prohibs1.append(prohibsre1)\n",
    "\n",
    "#Regex for the unit codes\n",
    "prohibs2 = []\n",
    "for element in prohibs1:\n",
    "    prohibsre = re.findall('\\w{3,4}\\d{4}', str(element))\n",
    "    prohibs2.append(prohibsre)\n",
    "    if not prohibsre:\n",
    "        prohibs2.pop()\n",
    "        prohibs2.append('NA')\n",
    "        \n",
    "#Removing duplicate values\n",
    "prohibs = []\n",
    "for element in prohibs2:\n",
    "    if element == 'NA':\n",
    "        prohibs.append(element)\n",
    "    else: \n",
    "        setelement = set(element)\n",
    "        prohibs.append(list(setelement))\n",
    "\n",
    "#Checking that all elements have been captured\n",
    "print(\"Length of prohibitions: \", len(prohibs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requirement / chief examiner extraction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of requirements:  400\n",
      "Length of chief examiners:  400\n"
     ]
    }
   ],
   "source": [
    "# Requirements\n",
    "reqs = []\n",
    "for element in htmlelements:\n",
    "    reqsre = re.findall('(?<=requirements<\\/h2>\\n<div>\\n<p>)\\w.*(?=<\\/p><p>)', element) \n",
    "    reqs.append(reqsre)\n",
    "    if not reqsre:\n",
    "        reqs.pop()\n",
    "        reqs.append('NA')\n",
    "        \n",
    "print(\"Length of requirements: \", len(reqs))\n",
    "\n",
    "# Chief Examiner\n",
    "chiefex = []\n",
    "for element in htmlelements:\n",
    "    chiefexre = re.findall('(?<=\\\">)\\w.*(?=</a>\\n<br/>\\n</p>\\n<p class=\\\"hbk-highlight-heading\\\">C)', element)\n",
    "    chiefex.append(chiefexre)\n",
    "    if not chiefexre:\n",
    "        chiefex.pop()\n",
    "        chiefex.append('TBA')\n",
    "        \n",
    "print(\"Length of chief examiners: \", len(chiefex))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outcome extraction\n",
    "Once the outcome section is extracted, each individual element is split on the dividing tags and appended into a new list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of outcomes:  400\n",
      "['[\"\\\\\\\\n<li>Validate the scientific literature to comprehend the progress within a specific research area;', 'Identify and apply the processes involved in the design, development and implementation of a research project;', 'Design, develop and implement a research project;', 'Acquire and analyse computer based data for graphical and tabular summarisation of findings;', 'Summarise research outcomes into scientific manuscripts in accordance with publication requirements;', 'Effectively and clearly communicate scientific principles and research findings in verbal and written form to a broad audience;', 'Identify and select techniques that are essential to the satisfactory completion and reporting of a research project', 'Apprehend the significance of ethics, laboratory etiquette and adherence to OHS', 'Recognize a critical problem and formulate a hypothesis to solve it; and', 'Interpret the research findings with reference to the existing literature</li>\\\\\\\\n\\']\"]']\n"
     ]
    }
   ],
   "source": [
    "#Initial extraction\n",
    "outcomes1 = []\n",
    "for element in htmlelements:\n",
    "    outcomesre = re.findall(\"(?<=Outcomes<\\/h2>)(.*?)(?=<\\/ol>)\", element, flags= re.MULTILINE|re.DOTALL) \n",
    "    outcomes1.append(outcomesre)\n",
    "    if not outcomesre:\n",
    "        outcomes1.pop()\n",
    "        outcomes1.append('NA')\n",
    "\n",
    "# Extracting everything after 'type=\"1\">'\n",
    "outcomes2 = []        \n",
    "for element in outcomes1:\n",
    "    outcomesre2 = re.findall('type=\"1\">(.*)' , str(element), flags= re.MULTILINE|re.DOTALL)\n",
    "    outcomes2.append(outcomesre2)\n",
    "    if not outcomesre2:\n",
    "        outcomes2.pop()\n",
    "        outcomes2.append('NA')\n",
    "        \n",
    "        \n",
    "# Splitting on the tag \n",
    "outcomes3 = []\n",
    "for element in outcomes2:\n",
    "    outcomes3.append(str(element).split('</li>\\\\\\\\n<li>'))\n",
    "    \n",
    "# Validation    \n",
    "print(\"Length of outcomes: \", len(outcomes3))\n",
    "print(outcomes3[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen in the above output, there is a problem at the start and end of each element with some tags that have been left behind. To fix this, the re.sub() method is used with various regular expressions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of outcomes:  400\n",
      "Validate the scientific literature to comprehend the progress within a specific research area;, Identify and apply the processes involved in the design, development and implementation of a research project;, Design, develop and implement a research project;, Acquire and analyse computer based data for graphical and tabular summarisation of findings;, Summarise research outcomes into scientific manuscripts in accordance with publication requirements;, Effectively and clearly communicate scientific principles and research findings in verbal and written form to a broad audience;, Identify and select techniques that are essential to the satisfactory completion and reporting of a research project, Apprehend the significance of ethics, laboratory etiquette and adherence to OHS, Recognize a critical problem and formulate a hypothesis to solve it; and, Interpret the research findings with reference to the existing literature\n"
     ]
    }
   ],
   "source": [
    "outcomes = []\n",
    "for element in outcomes3:\n",
    "    # Tags at the beginning\n",
    "    element = re.sub('\\[\\\"', '', str(element))\n",
    "    element = re.sub('\\\\\\\\', '', str(element))\n",
    "    element = re.sub('n<li>', '', str(element))\n",
    "    # Tags at the end\n",
    "    element = re.sub('</li>n', '', str(element))\n",
    "    element = re.sub('\\'\\]\\\"\\]', '', str(element))\n",
    "    # Removing leftover symbols\n",
    "    element = re.sub('\\[\\'|\\'\\]', '', str(element))\n",
    "    element = re.sub('(?<=\\s)\\'|\\'(?=\\W)', '', str(element))\n",
    "  \n",
    "    outcomes.append(element)\n",
    "    \n",
    "# Validation\n",
    "print(\"Length of outcomes: \", len(outcomes))\n",
    "print(outcomes[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Creating the JSON file\n",
    "\n",
    "### Formatting elements \n",
    "\n",
    "The next step is creating the JSON file, which requires a little bit more processing. For cetrain elements, where the value is not equal to 'NA', it needs to be nested, for example:\n",
    "\n",
    "  \"pre_requistics\": {\n",
    "                         \"pre_requistic\": [\n",
    "                              \"SCU1021\",\n",
    "                              \"SCU1611\",\n",
    "                              \"SCU1612\",\n",
    "                              \"OHS1000\",\n",
    "                              \"SCU1022\"\n",
    "                         ]\n",
    "                    },\n",
    "\n",
    "So, a loop is used to run through the initial lists. If the element is equal to 'NA' or 'TBA', it is appended into the final JSON list. Alternatively, the elements are put into a dictionary object (which fixes the formatting), and then appended to the final json list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prerequisites\n",
    "prereqsjson=[]\n",
    "\n",
    "for element in prereqs:\n",
    "    prereqs_dict = {}\n",
    "    if element == 'NA':\n",
    "        prereqsjson.append(element) \n",
    "    else:\n",
    "        prereqs_dict[\"pre_requistic\"]=element\n",
    "        prereqsjson.append(prereqs_dict) \n",
    "\n",
    "# Prohibitions        \n",
    "prohibsjson=[]\n",
    "for element in prohibs:\n",
    "    prohibs_dict = {}\n",
    "    if element == 'NA':\n",
    "        prohibsjson.append(element) \n",
    "    else:\n",
    "        prohibs_dict[\"prohibision\"]=element\n",
    "        prohibsjson.append(prohibs_dict)\n",
    "        \n",
    "# Requirements\n",
    "reqsjson=[]\n",
    "for element in reqs:\n",
    "    reqs_dict = {}\n",
    "    if element == 'NA':\n",
    "        reqsjson.append(element) \n",
    "    else:\n",
    "        reqs_dict[\"requirement\"]=element\n",
    "        reqsjson.append(reqs_dict)\n",
    "\n",
    "# Outcomes\n",
    "outcomejson=[]\n",
    "for element in outcomes:\n",
    "    outcome_dict = {}\n",
    "    if element == 'NA':\n",
    "        outcomejson.append(element) \n",
    "    else:\n",
    "        outcome_dict[\"outcome\"]=element\n",
    "        outcomejson.append(outcome_dict)\n",
    "        \n",
    "# Chief examiners\n",
    "chiefexjson=[]\n",
    "for element in chiefex:\n",
    "    chiefex_dict = {}\n",
    "    if element == 'TBA':\n",
    "        chiefexjson.append(element) \n",
    "    else:\n",
    "        chiefex_dict[\"chief_examiner\"]=element\n",
    "        chiefexjson.append(chiefex_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating dictionary and writing to file\n",
    "Now, using these newly formatted lists, along with the original unitid, title, and synopsis lists, we can create the JSON file.\n",
    "\n",
    "The steps are:\n",
    "\n",
    "1. Zip all the information elements together to create the values.\n",
    "2. Create a list of all the final keys.\n",
    "3. Make a loop to create the key:value pairs using another zip(), and append to a list.\n",
    "4. Format the JSON data to add \"units\" and \"unit\" tags as per exmaple JSON file.\n",
    "5. Write the final dictionary to a temporary file using json.dump().\n",
    "6. Remove unwanted symbols and write final file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the keys and values \n",
    "zipvalues = list(zip(unitid, title, synopsis, prereqsjson, prohibsjson, reqsjson, outcomejson, chiefexjson))\n",
    "keys = ['@id', 'title', 'synopsis', 'pre_requistics', 'prohibisions', 'requirements', 'outcomes', 'chief_examiners']\n",
    "\n",
    "# Creating a loop to add all elements to a list\n",
    "jsondict1 = []\n",
    "for i in range(len(zipvalues)):\n",
    "    dictionary = dict(zip(keys, zipvalues[i]))\n",
    "    jsondict1.append(dictionary)\n",
    "    \n",
    "#Formatting the json data\n",
    "jsondict2 = {}\n",
    "jsondict2['unit']=jsondict1\n",
    "jsondict3 = {}\n",
    "jsondict3['units']=jsondict2\n",
    "\n",
    "# Writing to the file\n",
    "with open('jsontemp.json', 'w') as outfile:   \n",
    "    json.dump(jsondict3, outfile, indent=4)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, removing the unwanted square brackets around the unitid, title, and synopsis elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening the file and reading\n",
    "with open('jsontemp.json', 'r' ) as f:\n",
    "    content = f.read()\n",
    "    # using thhe regex to remove unwanted symbols\n",
    "    content_new1 = re.sub('(?<=@id\":\\s)\\[', '', content, flags = re.MULTILINE | re.DOTALL)\n",
    "    content_new2 = re.sub('(?<=title\":\\s)\\[', '', content_new1, flags = re.MULTILINE | re.DOTALL)\n",
    "    content_new3 = re.sub('(?<=synopsis\":\\s)\\[', '', content_new2, flags = re.MULTILINE | re.DOTALL)\n",
    "    content_new4 = re.sub('\\](?=,)', '', content_new3, flags = re.MULTILINE | re.DOTALL)\n",
    "\n",
    "# Writing to the final file\n",
    "with open('30042585.json', 'w') as outfile:\n",
    "    outfile.write(content_new4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Creating the XML file\n",
    "\n",
    "In order to make the XML file, a string object is made for every relevant piece of information. The string objects include the start and end tags as they will appear in the final XML file. A placeholder ('=split=') is used so that the string can finally be broken up into a list.\n",
    "\n",
    "### Unit ID / title / synopsis string creation\n",
    "\n",
    "\n",
    "didnt want to delete apostrophes but wanted to delete single and double quotes so did a quite regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of unitid:  400\n",
      "Length of title:  400\n",
      "Length of synopsis:  400\n"
     ]
    }
   ],
   "source": [
    "# Unit ID\n",
    "unitidstring = ''\n",
    "for element in unitid:\n",
    "    unitidstring = unitidstring + \"=split=  <unit id=\"  + str(element) + \">\\n\"\n",
    "    \n",
    "#Removing square brackets and replacing single quotes with doubles\n",
    "unitidstring = re.sub('\\[|\\]', '', unitidstring)\n",
    "unitidstring = re.sub('\\'', '\\\"', unitidstring)\n",
    "\n",
    "unitidxml = unitidstring.split('=split=')\n",
    "del unitidxml[0]\n",
    "print(\"Length of unitid: \", len(unitidxml))\n",
    "    \n",
    "    \n",
    "# Title \n",
    "titlestring = ''\n",
    "for element in title:\n",
    "    titlestring = titlestring + \"=split=    <title>\\n    \"  + str(element) + \"\\n    </title>\\n\"\n",
    "\n",
    "#Removing single quotes\n",
    "titlestring = re.sub('(?<=\\[)\\'', '', titlestring)\n",
    "titlestring = re.sub('\"(?=\\])|\\'(?=\\])', '', titlestring)\n",
    "\n",
    "titlexml = titlestring.split('=split=')\n",
    "del titlexml[0]\n",
    "print(\"Length of title: \", len(titlexml))\n",
    "\n",
    "\n",
    "# Synopsis\n",
    "synopsisstring = ''\n",
    "for element in synopsis:\n",
    "    synopsisstring = synopsisstring + \"=split=    <synopsis>\\n    \" + str(element) + \"\\n    </synopsis> \\n\"\n",
    "\n",
    "synopsisxml = synopsisstring.split('=split=')\n",
    "del synopsisxml[0]\n",
    "print(\"Length of synopsis: \", len(synopsisxml))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-requisites / prohibitions string creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of pre-requisites:  400\n",
      "Length of prohibitions:  400\n"
     ]
    }
   ],
   "source": [
    "# Prerequisites\n",
    "prereqstring = ''\n",
    "\n",
    "for element in prereqs:\n",
    "    prereqstring = prereqstring + \"=split=\"\n",
    "    if element == \"NA\":\n",
    "        prereqstring = prereqstring + \"    <pre_requistics> \"\n",
    "        prereqstring = prereqstring + \"NA\"\n",
    "        prereqstring = prereqstring + \" </pre_requistics>\\n\"     \n",
    "    else:\n",
    "        prereqstring = prereqstring + \"    <pre_requistics>\\n\"\n",
    "        for element2 in element:\n",
    "            prereqstring = prereqstring + \"     <pre_requistic> \" + element2 + \" </pre_requistic>\\n\"\n",
    "        prereqstring = prereqstring + \"    </pre_requistics>\\n\"\n",
    "\n",
    "prereqxml = prereqstring.split('=split=')\n",
    "del prereqxml[0]\n",
    "print(\"Length of pre-requisites: \", len(prereqxml))\n",
    "\n",
    "\n",
    "# Prohibitions\n",
    "prohibstring = ''\n",
    "\n",
    "for element in prohibs:\n",
    "    prohibstring = prohibstring + \"=split=\"\n",
    "    if element == \"NA\":\n",
    "        prohibstring = prohibstring + \"    <prohibisions> \"\n",
    "        prohibstring = prohibstring + \"NA\"\n",
    "        prohibstring = prohibstring + \" </prohibisions> \\n\" \n",
    "    else:\n",
    "        prohibstring = prohibstring + \"    <prohibisions>\\n\"\n",
    "        for element2 in element:\n",
    "            prohibstring = prohibstring + \"     <prohibision> \" + element2 + \" </prohibision>\\n\"\n",
    "        prohibstring = prohibstring + \"    </prohibisions>\\n\"\n",
    "\n",
    "prohibxml = prohibstring.split('=split=')\n",
    "del prohibxml[0]\n",
    "print(\"Length of prohibitions: \", len(prohibxml))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requirements string creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of requirements:  400\n"
     ]
    }
   ],
   "source": [
    "reqstring = ''\n",
    "\n",
    "for element in reqs:\n",
    "    reqstring = reqstring + \"=split=\" \n",
    "    if element == \"NA\":\n",
    "        reqstring = reqstring + \"    <requirements> \"\n",
    "        reqstring = reqstring + \"NA\"\n",
    "        reqstring = reqstring + \" </requirements> \\n\"\n",
    "    else:\n",
    "        reqstring = reqstring + \"    <requirements>   \\n\" \n",
    "        reqstring = reqstring + \"     <requirement> \" + str(element) + \" </requirement>\\n\"\n",
    "        reqstring = reqstring + \"    </requirements> \\n\"\n",
    "\n",
    "reqsxml = reqstring .split('=split=')\n",
    "del reqsxml[0]\n",
    "print(\"Length of requirements: \", len(reqsxml))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outcomes string creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of outcomes:  400\n"
     ]
    }
   ],
   "source": [
    "outcomestring = ''\n",
    "\n",
    "for element in outcomes3:\n",
    "    outcomestring = outcomestring + \"=split=\"\n",
    "    \n",
    "    if element == \"NA\":\n",
    "        outcomestring = outcomestring + \"    <outcomes> \"\n",
    "        outcomestring = outcomestring + \"NA\"\n",
    "        outcomestring = outcomestring + \" </outcomes>\\n\"\n",
    "    else:\n",
    "        outcomestring = outcomestring + \"    <outcomes> \\n\"\n",
    "        for element2 in element:\n",
    "            outcomestring = outcomestring + \"     <outcome> \" + element2 + \" </outcome>\\n\"\n",
    "        outcomestring = outcomestring + \"    </outcomes>\\n\"        \n",
    "\n",
    "        \n",
    "outcomexml = outcomestring.split('=split=')\n",
    "del outcomexml[0]\n",
    "print(\"Length of outcomes: \", len(outcomexml))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chief examiners string creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of chief examiners:  400\n"
     ]
    }
   ],
   "source": [
    "chiefexstring = ''\n",
    "\n",
    "for element in chiefex:\n",
    "    chiefexstring = chiefexstring + \"=split=\"\n",
    "    if element == \"TBA\":\n",
    "        chiefexstring = chiefexstring + \"    <chief_examiners> \"\n",
    "        chiefexstring = chiefexstring + \"TBA\"\n",
    "        chiefexstring = chiefexstring + \" </chief_examiners>\\n\"\n",
    "        chiefexstring = chiefexstring + \"  </unit>\\n\"\n",
    "    else:\n",
    "        chiefexstring = chiefexstring + \"    <chief_examiners>\\n\" \n",
    "        chiefexstring = chiefexstring + \"     <chief_examiner> \" + str(element) + \" </chief_examiner>\\n\"\n",
    "        chiefexstring = chiefexstring + \"    </chief_examiners>\\n\"\n",
    "        chiefexstring = chiefexstring + \"  </unit>\\n\"\n",
    "    \n",
    "chiefexxml = chiefexstring.split('=split=')\n",
    "del chiefexxml[0]\n",
    "print(\"Length of chief examiners: \", len(chiefexxml))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining strings and writing to file\n",
    "\n",
    "The last step is to combine all of the strings together into a final string and write it all to a file. \n",
    "In additon, there is a lot of leftover formatting from previous sections such as '\\\\\\\\n', and leftover tags such as '\\<p>' In order to clean this up, we use regular expressions with re.sub() to replace any leftover symbols."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "length = len(unitid)\n",
    "index = 0\n",
    "finalxmlstring = ''\n",
    "finalxmlstring = finalxmlstring + \"<units>\\n\"\n",
    "\n",
    "# Creating a while loop to \n",
    "while index <= length-1:\n",
    "    finalxmlstring = finalxmlstring + unitidxml[index]\n",
    "    finalxmlstring = finalxmlstring + titlexml[index]\n",
    "    finalxmlstring = finalxmlstring + synopsisxml[index]\n",
    "    finalxmlstring = finalxmlstring + prereqxml[index]\n",
    "    finalxmlstring = finalxmlstring + prohibxml[index]\n",
    "    finalxmlstring = finalxmlstring + reqsxml[index]\n",
    "    finalxmlstring = finalxmlstring + outcomexml[index]\n",
    "    finalxmlstring = finalxmlstring + chiefexxml[index]\n",
    "    index+=1\n",
    "    \n",
    "finalxmlstring = finalxmlstring + \"</units>\"\n",
    "\n",
    "# Substituting the unwanted symbols\n",
    "finalxmlstring = re.sub('\\[', '', finalxmlstring)\n",
    "finalxmlstring = re.sub('\\]', '', finalxmlstring)\n",
    "finalxmlstring = re.sub('(?<=\\[)\\\"|(?<=\\[)\\'', '', finalxmlstring)\n",
    "finalxmlstring = re.sub('\"(?=\\])|\\'(?=\\])', '', finalxmlstring)    \n",
    "finalxmlstring = re.sub('<li>|</li>', '', finalxmlstring)\n",
    "finalxmlstring = re.sub('\\\\\\\\n\\'|\\\\\\\\n', '', finalxmlstring)\n",
    "finalxmlstring = re.sub('\\\\\\\\', '', finalxmlstring)\n",
    "finalxmlstring = re.sub('<p>|</p>', '', finalxmlstring)\n",
    "finalxmlstring = re.sub('<ul>|</ul>', '', finalxmlstring)\n",
    "finalxmlstring = re.sub('<ol princestart=\\\"0\\\" start=\\\"1\\\" type=\\\"i\\\">', '', finalxmlstring)\n",
    "\n",
    "\n",
    "text_file = open(\"30042585.xml\", \"w\")\n",
    "text_file.write(finalxmlstring)\n",
    "text_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Summary\n",
    "\n",
    "This task has demonstrated the basics of parsing raw text files in the Python. The main outcomes achieved while executing this task were: applying regular expressions for data extraction, string manipulation techniques, and JSON and XML file writing.\n",
    "\n",
    "There are things I could have done in a more 'pythonic' or quicker way. For instance, writing the XML file was time-consuming - I could have written the information to an XML file in a much shorter way, but the exact formatting specified in the assessment requirements took careful consideration to get the information nested in the perfect way. But ultimately, the XML and JSON files were completed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. References\n",
    "\n",
    "*Regular Expressions 101*. Retrieved from https://regex101.com/\n",
    "\n",
    "Python Software Foundation. (2019). *json â€” JSON encoder and decoder*. Retrieved from\n",
    "https://docs.python.org/2/library/json.html#module-json\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
